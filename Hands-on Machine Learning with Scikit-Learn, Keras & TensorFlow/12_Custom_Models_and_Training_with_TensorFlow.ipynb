{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Using TensorFlow like NumPy"
      ],
      "metadata": {
        "id": "VxjUiOVgRv1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "84B_F53UTiAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors and Operations"
      ],
      "metadata": {
        "id": "ejtwTHNoS1-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.constant([[1., 2., 3.], [4., 5., 6.]]) # matrix"
      ],
      "metadata": {
        "id": "KLzeMDMVS4P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.constant(42) # scalar"
      ],
      "metadata": {
        "id": "NsFz8lK-S-q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
        "t.shape"
      ],
      "metadata": {
        "id": "uE66aBVcTBwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.dtype"
      ],
      "metadata": {
        "id": "nABkTIm3TIMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t[:, 1:]"
      ],
      "metadata": {
        "id": "56fPJq4PTMgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t[..., 1, tf.newaxis]"
      ],
      "metadata": {
        "id": "HJ43ssqrTOy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t + 10"
      ],
      "metadata": {
        "id": "Wq2N6tlCTT4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.square(t)"
      ],
      "metadata": {
        "id": "9JxxoggFTUkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t @ tf.transpose(t)"
      ],
      "metadata": {
        "id": "637E8rKjTWqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors and NumPy"
      ],
      "metadata": {
        "id": "bq6LOEd6TaRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([2., 4., 5.])\n",
        "tf.constant(a)"
      ],
      "metadata": {
        "id": "rXilvmeaTcI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.numpy()"
      ],
      "metadata": {
        "id": "5pukpL3cTmAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.square(a)"
      ],
      "metadata": {
        "id": "SW_3-5fFTmys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.square(t)"
      ],
      "metadata": {
        "id": "iqI4LjuQToeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Type Conversions"
      ],
      "metadata": {
        "id": "_PjBpzxETqNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.constant(2.) + tf.constant(40) # InvalidArgumentError ... expected to be a float ...\n",
        "tf.constant(2.) + tf.constant(40., dtype=tf.float64) # InvalidArgumentError ... expected to be a double"
      ],
      "metadata": {
        "id": "mm4OfB9pTxeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = tf.constant(40, dtype=tf.float64)\n",
        "tf.constant(2.0) + tf.cast(t2, tf.float32)"
      ],
      "metadata": {
        "id": "vziRcoOfUCw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variables"
      ],
      "metadata": {
        "id": "tXfJWn1LUKbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
        "v"
      ],
      "metadata": {
        "id": "jjxLMJzIUMNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v.assign(2 * v)\n",
        "v[0, 1].assign(42)"
      ],
      "metadata": {
        "id": "u5dmjmAGUR9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v[:, 2].assign([0., 1.])\n",
        "v.scatter_nd_update(indices=[[0, 0], [1, 2]], updates=[100., 200.])"
      ],
      "metadata": {
        "id": "nmCOy7mCUWij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Customizing Models and Training Algorithms"
      ],
      "metadata": {
        "id": "sfPV-mvjUjCY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Loss Functions"
      ],
      "metadata": {
        "id": "Ax8yuvn2UnV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def huber_fn(y_true, y_pred):\n",
        "  error = y_true - y_pred\n",
        "  is_small_error = tf.abs(error) < 1\n",
        "  squared_loss = tf.square(error) / 2\n",
        "  linear_loss = tf.abs(error) - 0.5\n",
        "  return tf.where(is_small_error, squared_loss, linear_loss)"
      ],
      "metadata": {
        "id": "PS_d-BJGUpOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=huber_fn, optimizer=\"nadam\")\n",
        "model.fit(X_train, y_train, [...])"
      ],
      "metadata": {
        "id": "SI6dlQVWU7JA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving and Loading Models That Contain Custom Components"
      ],
      "metadata": {
        "id": "O5zlslWUVCnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"my_model_with_a_custom_loss.h5\",\n",
        "                                custom_objects={\"huber_fn\": huber_fn})"
      ],
      "metadata": {
        "id": "oOYioEneVG9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_huber(threshold=1.0):\n",
        "  def huber_fn(y_true, y_pred):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = tf.abs(error) < threshold\n",
        "    squared_loss = tf.square(error) / 2\n",
        "    linear_loss = threshold * tf.abs(error) - threshold ** 2 / 2\n",
        "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "  return huber_fn\n",
        "\n",
        "model.compile(loss=create_huber(2.0), optimizer=\"nadam\")"
      ],
      "metadata": {
        "id": "knmVhwOAVUAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"my_model_with_a_custom_loss_threshold_2.h5\",\n",
        "                                custom_objects={\"huber_fn\": create_huber(2.0)})"
      ],
      "metadata": {
        "id": "3LXZ8VlBVv2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HuberLoss(keras.losses.Loss):\n",
        "  def __init__(self, threshold=1.0, **kwargs):\n",
        "    self.threshold = threshold\n",
        "    super().__init__(**kwargs)\n",
        "  def call(self, y_true, y_pred):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = tf.abs(error) < self.threshold\n",
        "    squared_loss = tf.square(error) / 2\n",
        "    linear_loss = self.threshold * tf.abs(error) - self.threshold ** 2 / 2\n",
        "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "  def get_config(self):\n",
        "    base_config = super().get_config()\n",
        "    return {**base_config, \"threshold\": self.threshold}"
      ],
      "metadata": {
        "id": "vL3ynAQLWCuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\")"
      ],
      "metadata": {
        "id": "M5NNtqKTWk3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\",\n",
        "                                custom_objects={\"HuberLoss\": HuberLoss})"
      ],
      "metadata": {
        "id": "u7MeHf4uW1ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Activation Functions, Initializers, Regularizers, and Constraints"
      ],
      "metadata": {
        "id": "3xkVkuF9W-P4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_softplus(z): # return value is just tf.nn.softplus(z)\n",
        "  return tf.math.log(tf.exp(z) + 1.0)\n",
        "\n",
        "def my_glorot_initializer(shape, dtype=tf.float32):\n",
        "  stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
        "  return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
        "\n",
        "def my_l1_regularizer(weights):\n",
        "  return tf.reduce_sum(tf.abs(0.01 * weights))\n",
        "\n",
        "def my_positive_weights(weights):\n",
        "  return tf.where(weights < 0., tf.zeros_like(weights), weights)"
      ],
      "metadata": {
        "id": "sFigHfSoXKzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer = keras.layers.Dense(30, activation=my_softplus,\n",
        "                           kernel_initializer = my_glorot_initializer,\n",
        "                           kernel_regularizer = my_l1_regularizer,\n",
        "                           kernel_constraint = my_positive_weights)"
      ],
      "metadata": {
        "id": "1ClA6j0wX2or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
        "  def __init__(self, factor):\n",
        "    self.factor = factor\n",
        "  def __call__(self, weights):\n",
        "    return tf.reduce_sum(tf.abs(self.factor * weights))\n",
        "  def get_config(self):\n",
        "    return {\"factor\": self.factor}"
      ],
      "metadata": {
        "id": "NsI1il_3YCTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Metrics"
      ],
      "metadata": {
        "id": "U_9ez9AqYWQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])"
      ],
      "metadata": {
        "id": "7Wft5Sp6YYQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision = keras.metrics.Precision()\n",
        "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
      ],
      "metadata": {
        "id": "IMwftIQYYfOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
      ],
      "metadata": {
        "id": "vUPEkXEsYuZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p.result()"
      ],
      "metadata": {
        "id": "neP8p7q_Y4VI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p.variables"
      ],
      "metadata": {
        "id": "aJtSfvnLZj2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p.reset_states()"
      ],
      "metadata": {
        "id": "7tpTkc6jZlot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HuberMetrics(keras.metrics.Metric):\n",
        "  def __init__(self, threshold=1.0, **kwargs):\n",
        "    super().__init__(**kwargs) # handles base args\n",
        "    self.threshold = threshold\n",
        "    self.huber_fn = create_huber(threshold)\n",
        "    self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
        "    self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    metrics = self.huber_fn(y_true, y_pred)\n",
        "    self.total.assign_add(tf.reduce_sum(metrics))\n",
        "    self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
        "  def result(self):\n",
        "    return self.total / self.count\n",
        "  def get_config(self):\n",
        "    base_config = super().get_config()\n",
        "    return {**base_config, \"threshold\": self.threshold}"
      ],
      "metadata": {
        "id": "50OlRrdkZn7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Layers"
      ],
      "metadata": {
        "id": "Xpy7aVdGacZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))"
      ],
      "metadata": {
        "id": "jgjXG-RNafMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDense(keras.layers.Layer):\n",
        "  def __init__(self, units, activation=None, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.units = units\n",
        "    self.activation = keras.activations.get(activation)\n",
        "\n",
        "  def build(self, batch_input_shape):\n",
        "    self.kernel = self.add_weight(\n",
        "        name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
        "        initializer=\"glorot_normal\"\n",
        "    )\n",
        "    self.bias = self.add_weight(\n",
        "        name=\"bias\", shape=[self.units], initializer=\"zeros\"\n",
        "    )\n",
        "    super().build(batch_input_shape) # must be at the end\n",
        "\n",
        "  def call(self, X):\n",
        "    return self.activation(X @ self.kernel + self.bias)\n",
        "\n",
        "  def compute_output_shape(self, batch_input_shape):\n",
        "    return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
        "\n",
        "  def get_config(self):\n",
        "    base_config = super().get_config()\n",
        "    return {**base_config, \"units\": self.units,\n",
        "            \"activation\": keras.activations.serialize(self.activation)}"
      ],
      "metadata": {
        "id": "s4fEoUs4alPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyMultiLayer(keras.layers.Layer):\n",
        "  def call(self, X):\n",
        "    X1, X2 = X\n",
        "    return [X1 + X2, X1 * X2, X1 / X2]\n",
        "\n",
        "  def compute_output_shape(self, batch_input_shape):\n",
        "    b1, b2 = batch_input_shape\n",
        "    return [b1, b1, b1]"
      ],
      "metadata": {
        "id": "ag9fDAaLbhyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyGaussianNoise(keras.layers.Layer):\n",
        "  def __init__(self, stddev, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.stddev = stddev\n",
        "\n",
        "  def call(Self, X, training=None):\n",
        "    if training:\n",
        "      noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
        "      return X + noise\n",
        "    else:\n",
        "      return X\n",
        "\n",
        "  def compute_output_shape(self, batch_input_shape):\n",
        "    return batch_input_shape"
      ],
      "metadata": {
        "id": "R9gDgJNqcn1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Models"
      ],
      "metadata": {
        "id": "pqIqdLqmdExP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(keras.layers.Layer):\n",
        "  def __init__(self, n_layers, n_neurons, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.hidden = [keras.layers.Dense(n_neurons, activation=\"elu\",\n",
        "                                      kernel_initializer=\"he_normal\")\n",
        "                   for _ in range(n_layers)]\n",
        "\n",
        "  def call(self, inputs):\n",
        "    Z = inputs\n",
        "    for layer in self.hidden:\n",
        "      Z = layer(Z)\n",
        "    return inputs + Z"
      ],
      "metadata": {
        "id": "WUlPUoK_dHRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualRegressor(keras.models.Model):\n",
        "  def __init__(self, output_dim, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.hidden1 = keras.layers.Dense(30, activation=\"elu\",\n",
        "                                      kernel_initializer=\"he_normal\")\n",
        "    self.block1 = ResidualBlock(2, 30)\n",
        "    self.block2 = ResidualBlock(2, 30)\n",
        "    self.out = keras.layers.Dense(output_dim)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    Z = self.hidden1(inputs)\n",
        "    for _ in range(1 + 3):\n",
        "      Z = self.block1(Z)\n",
        "    Z = self.block2(Z)\n",
        "    return self.out(Z)"
      ],
      "metadata": {
        "id": "ChJrKaMLdh_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Losses and Metrics Based on Model Internals"
      ],
      "metadata": {
        "id": "FSWyXQZteHGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReconstructingRegressor(keras.models.Model):\n",
        "  def __init__(self, output_dim, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.hidden = [keras.layers.Dense(n_neurons, activation=\"elu\",\n",
        "                                      kernel_initializer=\"lecun_normal\")\n",
        "                   for _ in range(5)]\n",
        "    self.out = keras.layers.Dense(output_dim)\n",
        "\n",
        "  def build(self, batch_input_shape):\n",
        "    n_inputs = batch_input_shape[-1]\n",
        "    self.reconstruct = keras.layers.Dense(n_inputs)\n",
        "    super().build(batch_input_shape)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    Z = inputs\n",
        "    for layer in self.hidden:\n",
        "      Z = layer(Z)\n",
        "    reconstruction = self.reconstruct(Z)\n",
        "    recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
        "    self.add_loss(0.05 * recon_loss)\n",
        "    return self.out(Z)"
      ],
      "metadata": {
        "id": "D08fsssVeK7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computing Gradients Using Autodiff"
      ],
      "metadata": {
        "id": "kHvSFmcAe7a7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(w1, w2):\n",
        "  return 3 * w1 ** 2 + 2 * w1 * w2"
      ],
      "metadata": {
        "id": "dIZsLvrQfAhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1, w2 = 5, 3\n",
        "eps = 1e-6\n",
        "(f(w1 + eps, w2) - f(w1, w2)) / eps"
      ],
      "metadata": {
        "id": "qYKnMATCfEzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(f(w1, w2 + eps) - f(w1, w2)) / eps"
      ],
      "metadata": {
        "id": "el3g3Sc7fMao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
        "with tf.GradientTape() as tape:\n",
        "  z = f(w1, w2)\n",
        "\n",
        "gradients = tape.gradient(z, [w1, w2])"
      ],
      "metadata": {
        "id": "gnDzMk9afP6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradients"
      ],
      "metadata": {
        "id": "_ScxldaPfZ66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape() as tape:\n",
        "  z = f(w1, w2)\n",
        "\n",
        "dz_dw1 = tape.gradient(z, w1) # tensor 36.0\n",
        "dz_dw2 = tape.gradient(z, w2) # RuntimeError!"
      ],
      "metadata": {
        "id": "f-Ui5tLNfeD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape(persistent=True) as tape:\n",
        "  z = f(w1, w2)\n",
        "\n",
        "dz_dw1 = tape.gradient(z, w1) # tensor 36.0\n",
        "dz_dw2 = tape.gradient(z, w2) # tensor 10.0\n",
        "del tape"
      ],
      "metadata": {
        "id": "xN7T_fSjfrGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
        "with tf.GradientTape() as tape:\n",
        "  z = f(c1, c2)\n",
        "\n",
        "gradients = tape.gradient(z, [c1, c2]) # returns [tensor 36., tensor 10.]"
      ],
      "metadata": {
        "id": "nuZZFvJTf41I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape(persistent=True) as hessian_tape:\n",
        "  with tf.GradientTape() as jacobian_tape:\n",
        "    z = f(w1, w2)\n",
        "  jacobians = jacobian_tape.gradient(z, [w1, w2])\n",
        "hessians = [hessian_tape.gradient(jacobian, [w1, w2])\n",
        "            for jacobian in jacobians]\n",
        "del hessian_tape"
      ],
      "metadata": {
        "id": "p1n65NQDgIt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hessians"
      ],
      "metadata": {
        "id": "8TLUkFC6gkL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f(w1, w2):\n",
        "  return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  z = f(w1, w2)\n",
        "\n",
        "gradients = tape.gradient(z, [w1, w2])"
      ],
      "metadata": {
        "id": "o8nprEdMgqFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable([100.])\n",
        "with tf.GradientTape() as tape:\n",
        "  z = my_softplus(x)\n",
        "\n",
        "tape.gradient(z, [x])"
      ],
      "metadata": {
        "id": "KjWzMufig5de"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.custom_gradient\n",
        "def my_better_softplus(z):\n",
        "  exp = tf.exp(z)\n",
        "  def my_softplus_gradients(grad):\n",
        "    return grad / (1 + 1 / exp)\n",
        "  return tf.math.log(exp + 1), my_softplus_gradients"
      ],
      "metadata": {
        "id": "pZB_pgh0hHD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom Training Loops"
      ],
      "metadata": {
        "id": "N--RP9IjhjfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l2_reg = keras.regularizers.l2(0.05)\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg),\n",
        "    keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
        "])"
      ],
      "metadata": {
        "id": "a8ynYvgbhmzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_batch(X, y, batch_size=32):\n",
        "  idx = np.random.randint(len(X), size=batch_size)\n",
        "  return X[idx], y[idx]"
      ],
      "metadata": {
        "id": "rhcX6a_ph115"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_status_bar(iteration, total, loss, metrics=None):\n",
        "  metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
        "                        for m in [loss] + (metrics or [])])\n",
        "  end = \"\" if iteration < total else \"\\n\"\n",
        "  print(\"\\r{}/{} - \".format(iteration, total) + metrics, end=end)"
      ],
      "metadata": {
        "id": "JiuUr45mh-Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 5\n",
        "batch_size = 32\n",
        "n_steps = len(X_train) // batch_size\n",
        "optimizer = keras.optimizers.Nadam(lr=0.01)\n",
        "loss_fn = keras.losses.mean_squared_error\n",
        "mean_loss = keras.metrics.Mean()\n",
        "metrics = [keras.metrics.MeanAbsoluteEror()]\n",
        "\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
        "  for step in range(1, n_steps + 1):\n",
        "    X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
        "    with tf.GradientTape() as tape:\n",
        "      y_pred = model(X_batch, training=True)\n",
        "      main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
        "      loss = tf.add_n([main_loss] + model.losses)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variales))\n",
        "    mean_loss(loss)\n",
        "    for metric in metrics:\n",
        "      metric(y_batch, y_pred)\n",
        "    print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
        "  print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
        "  for metric in [mean_loss] + metrics:\n",
        "    metric.reset_states()"
      ],
      "metadata": {
        "id": "YUWTeUIeidZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensorFlow Functions and Graphs"
      ],
      "metadata": {
        "id": "G7mNbLa1j9kt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cube(x):\n",
        "  return x ** 3"
      ],
      "metadata": {
        "id": "fUzrDHu5kE-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cube(2)"
      ],
      "metadata": {
        "id": "4J6AmY6JkJYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cube(tf.constant(2.0))"
      ],
      "metadata": {
        "id": "DNkhEKtmkKV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_cube = tf.function(cube)\n",
        "tf_cube"
      ],
      "metadata": {
        "id": "j3HgDXkMkMfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_cube(2)"
      ],
      "metadata": {
        "id": "OvfG5zu8kPCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_cube(tf.constant(2.0))"
      ],
      "metadata": {
        "id": "4VnTbC3LkQhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def tf_cube(x):\n",
        "  return x ** 3"
      ],
      "metadata": {
        "id": "30hamA77kVtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_cube.python_function(2)"
      ],
      "metadata": {
        "id": "EPm7ie_UkZg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UvtPA4u_kbuy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}