{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TensorFlow Implementation\n",
        "\n",
        "- The Architecture of the Visual Cortex\n",
        "- Convolutional Layer\n",
        "- Filters\n",
        "- Stacking Multiple Feature Maps"
      ],
      "metadata": {
        "id": "MEMsyh6303CU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_sample_image"
      ],
      "metadata": {
        "id": "zfemoOLJ1LOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load sample images\n",
        "china = load_sample_image(\"china.jpg\") / 255\n",
        "flower = load_sample_image(\"flower.jpg\") / 255\n",
        "images = np.array([china, flower])\n",
        "batch_size, height, width, channels = images.shape\n",
        "\n",
        "# Create 2 filters\n",
        "filters = np.zeros(shape=(7, 7, channels, 2), dtype=np.float32)\n",
        "filters[:, 3, :, 0] = 1 # vertical line\n",
        "filters[3, :, :, 1] = 1 # horizontal line\n",
        "\n",
        "outputs = tf.nn.conv2d(images, filters, strides=1, padding=\"SAME\")\n",
        "\n",
        "plt.imshow(outputs[0, :, :, 1], cmap=\"gray\") # plot 1st image's 2nd feature map\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vkRmHLCg1QZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv = keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, padding=\"SAME\", activation=\"relu\")"
      ],
      "metadata": {
        "id": "Fj69a2sd1z81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TensorFlow Implementation 2\n",
        "\n",
        "- Memory Requirements\n",
        "- Pooling Layer"
      ],
      "metadata": {
        "id": "XzdBmMwL19aR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_pool = keras.layers.MaxPool2d(pool_size=2)\n",
        "\n",
        "output = tf.nn.max_pool(images,\n",
        "                        ksize=(1, 1, 1, 3),\n",
        "                        strides=(1, 1, 1, 3),\n",
        "                        padding=\"VALID\")\n",
        "\n",
        "depth_pool = keras.layers.Lambda(lambda X: tf.nn.max_pool(X, ksize=(1, 1, 1, 3), strides=(1, 1, 1, 3), padding=\"VALID\"))\n",
        "\n",
        "global_avg_pool = keras.layers.GlobalAvgPool2D()\n",
        "\n",
        "global_avg_pool = keras.layers.Lambda(lambda X: tf.reduce_mean(X, axis=[1, 2]))"
      ],
      "metadata": {
        "id": "6gRAlCjN2Y53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Architectures"
      ],
      "metadata": {
        "id": "84956o3Z23qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "DefaultConv2D = partial(keras.layers.Conv2D,\n",
        "                        kernel_size=3, activation=\"relu\", padding=\"SAME\")\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),\n",
        "    keras.layers.MaxPooling2D(pool_size=2),\n",
        "    DefaultConv2D(filters=128),\n",
        "    DefaultConv2D(filters=128),\n",
        "    keras.layers.MaxPooling2D(pool_size=2),\n",
        "    DefaultConv2D(filters=256),\n",
        "    DefaultConv2D(filters=256),\n",
        "    keras.layers.MaxPooling2D(pool_size=2),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(units=128, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(units=64, activation=\"relu\"),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(units=10, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "V5RT2Cu526lJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing a ResNet-34 CNN Using Keras"
      ],
      "metadata": {
        "id": "1ZP5U__K9kr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, strides=1,\n",
        "                        padding=\"SAME\", use_bias=False)\n",
        "\n",
        "class ResidualUnit(keras.layers.Layer):\n",
        "  def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.activation = keras.activations.get(activation)\n",
        "    self.main_layers = [\n",
        "        DefaultConv2D(filters, strides=strides),\n",
        "        keras.layers.BatchNormalization(),\n",
        "        self.activation,\n",
        "        DefaultConv2D(filters),\n",
        "        keras.layers.BatchNormalization()\n",
        "    ]\n",
        "    self.skip_layers = []\n",
        "    if strides > 1:\n",
        "      self.skip_layers = [\n",
        "          DefaultConv2D(filters, kernel_size=1, strides=strides),\n",
        "          keras.layers.BatchNormalization()\n",
        "      ]\n",
        "\n",
        "  def call(self, inputs):\n",
        "    Z = inputs\n",
        "    for layer in self.main_layers:\n",
        "      Z = layer(Z)\n",
        "    skip_Z = inputs\n",
        "    for layer in self.skip_layers:\n",
        "      skip_Z = layer(skip_Z)\n",
        "    return self.activation(Z + skip_Z)"
      ],
      "metadata": {
        "id": "4zunC8s89tSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(DefaultConv2D(64, kernel_size=7, strides=2, input_shape=[224, 224, 3]))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.Activation(\"relu\"))\n",
        "model.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\"))\n",
        "prev_filters = 64\n",
        "for filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\n",
        "  strides = 1 if filters == prev_filters else 2\n",
        "  model.add(ResidualUnit(filters, strides=strides))\n",
        "  prev_filters = filters\n",
        "model.add(keras.layers.GlobalAvgPool2D())\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "OM09mkJ7-um6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Pretrained Models From Keras"
      ],
      "metadata": {
        "id": "oJM04kqo_Xh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.applications.resnet50.ResNet50(weights=\"imagenet\")\n",
        "\n",
        "image_resized = tf.image.resize(image, [224, 224])\n",
        "\n",
        "inputs = keras.application.resnet50.preprocess_input(image_resized * 255)\n",
        "\n",
        "Y_proba = model.predict(inputs)\n",
        "\n",
        "top_K = keras.applications.resnet50.decode_predictions(Y_proba, top=3)\n",
        "for image_index in range(len(images)):\n",
        "  print(\"Image #{}\".format(image_index))\n",
        "  for class_id, name, y_proba in top_K[image_index]:\n",
        "    print(\"  {} - {:12s} {:.2f}%\".format(class_id, name, y_proba * 100))\n",
        "  print()"
      ],
      "metadata": {
        "id": "VJtt2C_5_aCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pretrained Models for Transfer Learning"
      ],
      "metadata": {
        "id": "1UDh4Hj_AJmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "dataset, info = tfds.load(\"tf_flowers\", as_supervised=True, with_info=True)\n",
        "dataset_size = info.splits[\"train\"].num_examples # 3670\n",
        "class_names = info.features[\"label\"].names\n",
        "n_classes = info.features[\"label\"].num_classes # 5"
      ],
      "metadata": {
        "id": "iLrHjL5PALnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_split, valid_split, train_split = tfds.Split.TRAIN.subsplit([10, 15, 75])\n",
        "\n",
        "test_set = tfds.load(\"tf_flowers\", split=test_split, as_supervised=True)\n",
        "valid_set = tfds.load(\"tf_flowers\", split=valid_split, as_supervised=True)\n",
        "train_set = tfds.load(\"tf_flowers\", split=train_split, as_supervised=True)"
      ],
      "metadata": {
        "id": "nR48APwuAdKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(image, label):\n",
        "  resized_image = tf.image.resize(image, [224, 224])\n",
        "  final_image = keras.applications.xception.preprocess_input(resized_image)\n",
        "  return final_image, label\n",
        "\n",
        "batch_size = 32\n",
        "train_set = train_set.shuffle(1000).repeat()\n",
        "train_set = train_set.map(preprocess).batch(batch_size).prefetch(1)\n",
        "valid_set = valid_set.map(preprocess).batch(batch_size).prefetch(1)\n",
        "test_set = test_set.map(preprocess).batch(batch_size).prefetch(1)"
      ],
      "metadata": {
        "id": "5zCcgjzkAvRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = keras.applications.xception.Xception(wweights=\"imagenet\", include_top=False)\n",
        "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "output = keras.layers.Dense(n_classes, activation=\"softmax\")(avg)\n",
        "model = keras.models.Model(inputs=base_model.input, outputs=output)"
      ],
      "metadata": {
        "id": "FGuV_NE6BJsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "optimizer = keras.optimizers.SGD(lr=0.2, momentum=0.9, decay=0.01)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "history = model.fit(train_set,\n",
        "                    steps_per_epoch=(0.75 * dataset_size / batch_size),\n",
        "                    validation_data=valid_set,\n",
        "                    validation_steps=int(0.15 * dataset_size / batch_size),\n",
        "                    epochs=5)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = True\n",
        "\n",
        "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0.001)\n",
        "model.compile(...)\n",
        "history = model.fit(...)"
      ],
      "metadata": {
        "id": "0N7c3pugBKWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification and Localization"
      ],
      "metadata": {
        "id": "xDVk0diNCLGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = keras.applications.xception.Xception(weights=\"imagenet\",\n",
        "                                                  include_top=False)\n",
        "\n",
        "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "class_output = keras.layers.Dense(n_classes, activation=\"softmax\")(avg)\n",
        "loc_output = keras.layers.Dense(4)(avg)\n",
        "model = keras.models.Model(inputs=base_model.input,\n",
        "                           outputs=[class_output, loc_output])\n",
        "model.compile(loss=[\"sparse_categorical_crossentropy\", \"mse\"],\n",
        "              loss_weights=[0.8, 0.2],\n",
        "              optimizer=optimizer, metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "pECBEjuSCM8X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}